#!/bin/bash

## Create a daily backup of the local Drupal instance's:
## 1. database content
## 2. static files
## 3. drupal document root
## This script is run from druadmin's crontab

# Must be this user to run this script
USER=druadmin
if [ "`/usr/bin/id -urn`" != "$USER" ] ; then
  echo "You must be the $USER user to execute this script - exiting."
  exit 1
fi

DRUSH="/home/druadmin/.composer/vendor/bin/drush"

# Get local drush alias
# Drush Alias - only need one as all webheads share the same database instance and the same static files
# All drush aliases can be found in ~/$USER/.drush/aliases.drushrc.php
# Our convention for Drush aliases: @rhel-[test|stage|prod][0-9]
SRC_DRUSH=`$DRUSH site-alias --local-only`
if [ $? -ne 0 ] ; then
  echo -e "Failed to get alias for local Drupal instance - exiting \n"
  exit 1
fi

TODAY=`date +%Y%m%d`
SEVENDAYSAGO=`date -d 'now - 7 days' "+%Y%m%d"`
BACKUP_DIR="/drupalbackup/$TODAY"

# Names for the MySQL dump file: plain and gzipped
SQL_DUMP="$BACKUP_DIR/`echo $SRC_DRUSH | sed 's/@//'`_db_$TODAY.sql"

# Where the drupal document root and static files are located
# Each subdirectory will go into its own gzipped TAR file
WEBHEAD_ROOT=/var/www/vhosts/webhead
SUBDIR_LIST="sites_default_files drupal"

mkdir -p $BACKUP_DIR

# Create MySQL database dump file
echo -e "\nCreating SQL dump file from $SRC_DRUSH Drupal instance \n"
$DRUSH $SRC_DRUSH sql-dump --result-file=$SQL_DUMP --gzip
if [ ! -s "${SQL_DUMP}.gz" ] ; then
  echo -e "\nFailed to create the MySQL database dump file $SQL_DUMP - exiting \n"
  exit 1
fi

# Create a gzipped TAR file of each subdirectory in SUBDIR_LIST
for SUBDIR in $SUBDIR_LIST; do

  # Name of the gzipped TAR file
  SUBDIR_TAR_GZ="$BACKUP_DIR/`echo $SRC_DRUSH | sed 's/@//'`_${SUBDIR}_${TODAY}.tar.gz"

  # Create the gzipped TAR file
  echo -e "\nCreating gzipped $SUBDIR directory archive... \n"

  # -C: tar from within the SUBDIR directory
  #   Per akohler: Exclude the subdirectory itself, because it has a different
  #   name in the development environment
  # --exclude:
  #   OS-X-specific .apdisk files
  #   OS-X-specific .DS_Store files
  #   OS-X-specific .TemporaryItems directories
  #   Windows-specific Thumbs.db files
  # ./.check_mount, which Nagios uses to verify that the file system is mounted
  tar czf $SUBDIR_TAR_GZ -C $WEBHEAD_ROOT/$SUBDIR .    \
    --exclude ".apdisk"           \
    --exclude ".DS_Store"         \
    --exclude ".TemporaryItems"   \
    --exclude "Thumbs.db"         \
    --exclude "./.check_mount"    \
    --exclude ".snapshot" > /dev/null 2>&1
  # Exit codes 0 (sucess) and 1 (file changed) are acceptable - anything else is fatal error
  # Exit code 1: Periodically Varnish cache runs status.php, which adds and deletes a file in sites_default_files
  if [ $? -ne 0 -a $? -ne 1 ] ; then
    echo -e "\nFailed to create the '$SUBDIR_TAR_GZ' archive - exiting \n"
    exit 1
  fi
done

# -------------------------------------------------------------
# Expire Backups - Only Keep Seven Days
# -------------------------------------------------------------

BACKUP_TOPLEVEL=`dirname $BACKUP_DIR`

BACKUP_DATES=`find $BACKUP_TOPLEVEL -type d -name "[0-9]*" -printf "%f\n" | sort -n`

# Each backup directory is named in YYYYMMDD format based on the day it was created.
# If a directory's name is older than seven days ago, the directory is removed.
if [ -n "$BACKUP_DATES" ] ; then
  for DATE in $BACKUP_DATES ; do
    if [ $(( $DATE - $SEVENDAYSAGO )) -lt 0 ] ; then
      rm -rf $BACKUP_TOPLEVEL/$DATE
    fi
  done
fi
